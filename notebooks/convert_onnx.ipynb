{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9fqhVzKi4Mn"
      },
      "outputs": [],
      "source": [
        "%pip install -q onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1NmdSEsnfkc9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D16EdtwEfc4s"
      },
      "outputs": [],
      "source": [
        "class BERTRegressor(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = base_model\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "             nn.Dropout(0.5),\n",
        "             nn.Linear(self.bert.config.hidden_size, 128),\n",
        "             nn.GELU(),\n",
        "             nn.Linear(128, 1),\n",
        "         )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        cls = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0]\n",
        "\n",
        "        return self.regressor(cls).squeeze(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wOx_8OLnfsHG"
      },
      "outputs": [],
      "source": [
        "# Load base model and custom model\n",
        "base_model = AutoModel.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
        "model = BERTRegressor(base_model)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/BERT_rating_prediction/model/weights.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# ONNX export doesn't require GPU\n",
        "model.to(\"cpu\")\n",
        "\n",
        "# Prepare dummy input\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
        "inputs = tokenizer(\"This is a dummy input.\", return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "input_ids = inputs[\"input_ids\"]\n",
        "attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "# Export to ONNX\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    (input_ids, attention_mask),\n",
        "    \"/content/drive/MyDrive/BERT_rating_prediction/model/bert_regressor.onnx\",\n",
        "    input_names=[\"input_ids\", \"attention_mask\"],\n",
        "    output_names=[\"output\"],\n",
        "    dynamic_axes={\n",
        "        \"input_ids\": {0: \"batch_size\", 1: \"seq_len\"},\n",
        "        \"attention_mask\": {0: \"batch_size\", 1: \"seq_len\"},\n",
        "        \"output\": {0: \"batch_size\"}\n",
        "    },\n",
        "    opset_version=17\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
